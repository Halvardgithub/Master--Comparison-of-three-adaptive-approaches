---
title: "Spatial Wakefield and geojson handeling"
author: "Halvard"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Loading and processing the geosjon file
A geojson file for Spain and we are interested in the levels for autonomous regions and provinces. We descount the two islands, as they are less interesting in a spatial analysis. The goal is to make informative maps of the regions, as well as presenting the risk syrfaces and resutls of the analysis as a heatmap for the regions. For the analysis, we need the adjacency structure as a simple graph, or an adjacency matrix, and columns containing the name of the province and autonomous region in question. This must then also be harmonized with the disease data.

Some of the autonomous regions, like the island regions Illes Baleares and Canary Islands, and two cities in Morocco, namely Ceuta and Melilla, should be removed from all the data.

```{r}
library(sf)
library(spdep)
library(dplyr)
library(ggplot2)

shp_prov <- st_read("Data/Provinces/Provincias_ETRS89_30N.shp")
colnames(shp_prov) <- c("Index", "ProvName", "ProvName1", "CCAA_Index", "CCAA_Name", "geometry")
CCAA_to_remove <- c("Illes Balears", "Canarias", "Ceuta", "Melilla")
shp_prov <- filter(shp_prov, !CCAA_Name %in% CCAA_to_remove)

plot(shp_prov["ProvName"], key.pos = NULL, main = "Map of the provinces of Spain")

# shp_AutReg <- st_read("Data/AutonomousRegions/Comunidades_Autonomas_ETRS89_30N.shp")
# colnames(shp_AutReg) <- c("Index", "CCAA_Name", "CCAA_Name1", "geometry")
# plot(shp_AutReg["CCAA_Name1"], key.pos = NULL, main = "Map of the autonomous regions of Spain")

# shp_prov <- st_read("Data/Provinces/Provincias_ETRS89_30N.shp")
# 
# shp_AutReg <- st_read("Data/AutonomousRegions/Comunidades_Autonomas_ETRS89_30N.shp")
# 
# colnames(shp_prov) <- c("Index", "ProvName", "ProvName1", "CCAA_Index", "CCAA_Name", "geometry")
# colnames(shp_AutReg) <- c("Index", "CCAA_Name", "CCAA_Name1", "geometry")


shp_prov_large <- shp_prov |>
  group_by(CCAA_Name) |>
  summarise(geometry = st_union(geometry))

# Create the ggplot2 map
MapSpainFig <- ggplot() +
geom_sf(data = shp_prov, fill = NA, color = "black", linewidth = 0.6) +
geom_sf(data = shp_prov_large, fill = NA, color = "black", linewidth = 1.15) +
labs(title = "Map of autonomous regions and provinces in Spain") +
theme_minimal()
MapSpainFig

```


## Code from Andrea and Miguel for data preperation and plotting

```{r}
library(sf)
library(ggplot2)
library(dplyr)

ss_provinces = read_sf("Data/Provinces/Provincias_ETRS89_30N.shp")

ss_ar = read_sf("Data/AutonomousRegions/Comunidades_Autonomas_ETRS89_30N.shp")

#ggplot() + geom_sf(data = ss_provinces) + geom_sf(data = ss_ar)

# we only work with mainland Spain, remove the islands

out = c("Islas Baleares", "Las Palmas", "Santa Cruz de Tenerife", "Ceuta", "Melilla")

out2 = c("Canarias", "Islas Baleares", "Ceuta", "Melilla")

ss_provinces = ss_provinces |> filter(!(Texto %in% out))

ss_ar = ss_ar |> filter(!(Texto %in% out2))

ggplot() +

  geom_sf(data = ss_ar, color="black") + #do not really need this line

  geom_sf(data=ss_provinces, fill=NA, color="grey") +

  geom_sf(data = ss_ar, color="black", fill=NA,linewidth = 0.4)
```


# Making map figures for the report
First up is maps with edges to illustrate the Wakefield neighborhood structure. One map with grouping based on inside or across autonomous regions and one based on a "shocked" subset of provinces. Show one edge groups with red edges and the other as blue.

```{r}
include <- c("15", "24", "27", "32", "33", "36", "49") 

include2 <- c("03", "12")



ss_provinces_example = filter(ss_provinces, Codigo %in% include)

ss_ar_example = filter(ss_ar, Codigo %in% include2)

centroids_example <- st_centroid(ss_provinces_example)

nb_example <- poly2nb(ss_provinces_example)

edge_list_example <- list()
region_from <- c()
region_to <- c()

for (i in seq_along(nb_example)) {
  neighbors <- nb_example[[i]]
  if (length(neighbors) == 0) next
  
  for (j in neighbors) {
    # Store the line geometry
    edge_list_example <- append(edge_list_example, 
                        list(st_linestring(rbind(st_coordinates(centroids_example[i, ]), 
                                                 st_coordinates(centroids_example[j, ])))))
    
    # Store region names or IDs
    region_from <- c(region_from, i)
    region_to <- c(region_to, j)
  }
}

edges_sf_example <- st_sf(geometry = st_sfc(edge_list_example, 
                                            crs = st_crs(ss_provinces_example)), 
                  from = region_from, to = region_to)

weights_example1 <- c(0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1)

weights_example2 <- c(1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0)

edges_sf_example$Wex1 <- factor(weights_example1)
edges_sf_example$Wex2 <- factor(weights_example2)

ExamplePlot1 <- ggplot() +
  geom_sf(data = ss_ar_example, color="black") + #do not really need this line
  geom_sf(data=ss_provinces_example, color="grey") +
  geom_sf(data = ss_ar_example, color="black", fill=NA,linewidth = 0.4) +
  geom_sf(data = centroids_example, color = "black", size = 2)  + # Centroids
  geom_sf(data = edges_sf_example, aes(color = Wex1), show.legend = FALSE) +
  scale_color_manual(values = c("0" = "blue", "1" = "red")) +
  theme(axis.text = element_blank(), axis.ticks = element_blank()) +
  theme_minimal()

ExamplePlot2 <- ggplot() +
  geom_sf(data = ss_ar_example, color="black") + #do not really need this line
  geom_sf(data=ss_provinces_example, color="grey") +
  geom_sf(data = ss_ar_example, color="black", fill=NA,linewidth = 0.4) +
  geom_sf(data = centroids_example, color = "black", size = 2)  + # Centroids
  geom_sf(data = edges_sf_example, aes(color = Wex2), show.legend = FALSE) +
  scale_color_manual(values = c("0" = "blue", "1" = "red")) +
  theme(axis.text = element_blank(), axis.ticks = element_blank()) +
  theme_minimal()

examplePlots <- ggarrange(ExamplePlot1, ExamplePlot2, ncol = 2)

example_edgeStructuresFigure <- annotate_figure(examplePlots, 
                                top = text_grob("Two examples of grouping the edges",
                                face = "bold", size = 30))

#ggsave("Plots//ExampleEdgesFigure.png", plot = example_edgeStructuresFigure, height = 13, width = 21,  units = "cm",  dpi = 300)


# edgeplot_example1 <- ggplot() +
#   geom_sf(data = ss_provinces, fill = NA, color = "grey") +  # Provinces
#   geom_sf(data = ss_ar, color="black", fill=NA,linewidth = 0.4) + # Autonomous regions
#   geom_sf(data = centroids, color = "red", size = 2) +  # Centroids
#   geom_sf(data = edges_sf, aes(linewidth = edge_value_ABYM_86), color = "blue") + 
#   scale_linewidth(range = c(0.2, 1.7), breaks = pretty_breaks(n = 4)) +  
#   labs(x = "Adaptive BYM",y = "n = 86") +
#   theme_minimal() +
#   theme(axis.text = element_blank(),axis.ticks = element_blank(),
#         axis.title.x = element_text(size = 18), axis.title.y = element_text(size = 18)) +
#    guides(linewidth = guide_legend(title = "Width mapping"))
```





# Spatial Wakefield model

The implementation will be in rgeneric and be very similar to the temporal case from my master project in the fall. The main difference is that the previous conflict and non-conflict points are now instead transitions inside an autonomous regions and transitions involving two autonomous regions. The expectation is that regions in the same autonomous regions have more in common than regions in different autonomous regions. Additionally, the function will need the dataframe with the administrative levels as an input variable to construct the precision matrix $Q$. Lets implement this with the dataframe created above as an input.

NB: There must be consistent ordering of regions and so on for the weight matrix to coincide with the supplied data. 

```{r}
library(INLA)

inla.rgeneric.AdaptiveICAR = function(
  cmd = c("graph", "Q", "mu", "initial", "log.norm.const","log.prior", "quit"),
  theta = NULL)
{
  #Input:
  #df: contains the relevant information for the areal data
  #prior_str is either Gamma0.005, Gamma0.00005 or PC    , might not need this, but useful for sensitivity analysis, or just include an argument which is the p and a used in the pc.priors
  # maybe also pass the adjacency graph/matrix as an argument, can then iterate through the non-zero entries maybe
  
  envir = parent.env(environment())
  
  interpret_theta <- function() { return(list(tau1 = exp(theta[1L]), 
                                              tau2 = exp(theta[2L])))}
  
  graph <- function() {return(Q())}
  
  Q <- function() {
    N <- nrow(df) #df is passed as an argument, the number of regions
    R1 <- matrix(0, nrow = N, ncol = N) #non-conflict
    R2 <- matrix(0, nrow = N, ncol = N) #conflict
    
    #assume the adjacency matrix is called AMat, then
    non_zero_indices <- which(AMat == 1, arr.ind = TRUE)
    
    for (k in seq_len(nrow(non_zero_indices))) { #nrow?
      i <- non_zero_indices[k, 1]
      j <- non_zero_indices[k, 2]
      
      if(df[i, "autReg"] == df[j, "autReg"]){
        R1[i, j] <- -1
        R1[i, i] <- R1[i, i] + 1
      }
      else{
        R2[i, j] <- -1
        R2[i, i] <- R2[i, i] + 1
      }
    }
    
    gv <- exp(1 / N * sum(log(diag(INLA:::inla.ginv(R1 + R2))))) #scaling constant
    R_star_list <- list(R1 = R1*gv, R2 = R2*gv)
    
    p <- interpret_theta()
    Q <- R_star_list$R1 * p$tau1 + R_star_list$R2 * p$tau2
    return(inla.as.sparse(Q)) #sparse representation
    
    
    for( i in 1:(N - 1)){
      if(i %in% conflict_years | (i + 1) %in% conflict_years) {
        R2[c(i, i+1), c(i, i+1)] <- R2[c(i, i+1), c(i, i+1)] + c(1, -1, -1, 1)
      }
      else {
        R1[c(i, i+1), c(i, i+1)] <- R1[c(i, i+1), c(i, i+1)] + c(1, -1, -1, 1)
      }
    }
    gv <- exp(1 / N * sum(log(diag(INLA:::inla.ginv(R1 + R2))))) #scaling constant
    R_star_list <- list(R1 = R1*gv, R2 = R2*gv)
    
    p <- interpret_theta()
    Q <- R_star_list$R1 * p$tau1 + R_star_list$R2 * p$tau2
    return(inla.as.sparse(Q)) #sparse representation
  }
  
  mu <- function() {return(numeric(0))}
  
  initial <- function() {return(c(4, 4))}#Default initial for precisions is 4
  
  log.norm.const <- function() {return(numeric(0))}
  
  log.prior <- function() {#default: shape = 1, rate = 0.00005
    p <- interpret_theta()
    if(prior_str == "PC"){
      prior <- inla.pc.dprec(p$tau1, u = 1, alpha = 0.01, log=TRUE) + log(p$tau1) +
          inla.pc.dprec(p$tau2, u = 1, alpha = 0.01, log = TRUE) + log(p$tau2)
      return(prior)
    } else if(prior_str == "Gamma0,005"){
      prior <- dgamma(p$tau1, shape = 1, rate = 0.005, log = TRUE) + log(p$tau1) +
      dgamma(p$tau2, shape = 1, rate = 0.005, log = TRUE) + log(p$tau2)
      return(prior)
    }
    prior <- dgamma(p$tau1, shape = 1, rate = 0.00005, log = TRUE) + log(p$tau1) +
    dgamma(p$tau2, shape = 1, rate = 0.00005, log = TRUE) + log(p$tau2)
    return(prior) 
  }
  
  quit <- function() {return(invisible())}
  
  #to ensure theta is defined
  if (!length(theta)) theta = initial()
  
  vals <- do.call(match.arg(cmd), args = list())
  return(vals)
}
```

To initialize the resulting latent term we call the rgeneric function as below:
```{r}
AICAR_model <- inla.rgeneric.define(inla.rgeneric.AdaptiveICAR, 
                                    df = df, AMat = AMAT, prior_str = "PC") #might pass u and a

```

# Load and preprocess the disease data
The data for male mortality cases nationally and at province level is collected in 5-year age bins for each disease. These must be aggregated to the total cases per disease in each province and summarised in a matrix called ObservedCases. Furthermore, we calculate the expected cases based on the population per age bin in each province, which is denoted as ExpectedCases. Lastly, some choice of the mortality causes must be done. For instance, some causes are extremely rare, for instance only 1 or 2 cases nationally. Therefore, we implemented a lower limit of an average of 2 cases per province, which for 47 provinces equald 94 cases nationally. Additionally, some of the mortality causes are not disease related, for instance homocides, and should also be removed. 

```{r}
library(readr)
library(tidyr)

#Calculation of expected observation

# load("Expected.Rdata")
# 
# colnames(Expected) <- gsub("^\\d+\\s+", "", colnames(Expected))
# rownames(Expected) <- gsub("^\\d+\\s+", "", rownames(Expected))
# 
# Expected2 <- as.data.frame(Expected)
# 
# saveRDS(Expected2, "ExpectedCasesMiguel.rds")

#Mortality data

# Mortality_df <- read_csv2("Mortality.csv")
# 
# Mortality_df <- Mortality_df[, c(1, 3, 4)]
# colnames <- colnames(Mortality_df)
# 
# df_wide <- Mortality_df %>%
#   pivot_wider(names_from = colnames[1], values_from = colnames[3], values_fill = list(cases = NA))
# df_wide <- df_wide[, -43] #remove a joint column
# 
# df_matrix <- as.matrix(df_wide[, -1]) #remove the province column
# 
# ObservedCases <- as.matrix(ExpectedCases) #I made sure everything aligned, both rows and cols
# 
# ObservedCases[1:47, 1:102] <- df_matrix[1:47, 1:102]
# 
# sparse_columns <- as.numeric(which(colSums(df_matrix) < 94)) # 47*2=94, was 16 columns
# 
# ObservedCases <- ObservedCases[, -sparse_columns] #removed the 16 sparse columns
# 
# saveRDS(ObservedCases, "ObservedCases.rds")
# 
# ObservedCases <- readRDS("ObservedCases.rds")
# 
#ExpectedCases <- readRDS("ExpectedCasesMiguel.rds")
#
#ExpectedCases <- as.matrix(ExpectedCases)
# 
# ExpectedCases <- ExpectedCases[, -sparse_columns]
# 
# saveRDS(ExpectedCases, "ExpectedCasesMiguel.rds")

#Population data
# Pop_data <- read_csv2("PopXProvincesXAge.csv")
# 
# colnames(Pop_data)
# 
# library(dplyr)
# 
# Pop_data_total <- Pop_data |>
#   group_by(Provinces) |>  # Group by Provinces
#   summarise(Total_Population = sum(Total, na.rm = TRUE))  # Sum Population column
# 
# saveRDS(Pop_data_total, "PopulationData.rds")
```



# Perform spatial analysis with INLA
